## 7.x 的新特性（该笔记基于2.x版本）

```
去除了 type 

1.7以后的 es 不用 version 了 而是使用 if_seq_no 和 if_primary_term 来控制版本

_mapping  去除了映射 type 7.x已经没有type的概念了。

5.x 以后删除 missing api


根据官方文档显示，出现该错误是因为5.x之后，Elasticsearch对排序、聚合所依据的字段用单独的数据结构(fielddata)缓存到内存里了，但是在text字段上默认是禁用的，如果有需要单独开启，这样做的目的是为了节省内存空间。
Fielddata会耗费大量的堆内存，尤其是在加载大文件时。一旦fielddata被加载到内存中，他会在segment的生命周期一直存在。而且，搜索时处理fielddata还会导致速度下降甚至严重延迟，所以默认fielddata被禁用。

PUT
http://localhost:9200/megacorp/_mapping
{
  "properties": {
    "about": { 
      "type":     "text",
      "fielddata": true
    }
  }
}
about 是指要开启的字段


string类型在ElasticSearch 旧版本中使用较多，从ElasticSearch 5.x开始不再支持string，由text和keyword类型替代。 
text 
当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。
设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合。 
keyword 
keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。
如果字段需要进行过滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。
keyword类型的字段只能通过精确值搜索到。
```

# 1、数据输入和输出

## 1、什么是文档

```
在大多数应用中，多数实体或对象可以被序列化为包含键值对的 JSON 对象。一个键可以是一个字段或字段的名称，
一个值可以是一个字符串，一个数字，一个布尔值，另一个对象，一些数组值，或一些其他特殊类型诸如表示日期的字符串，或代表一个地理位置的对象
```

```
通常情况下，我们使用的术语对象和文档是可以互相替换的。不过，有一个区别：一个对象仅仅是类似于 hash、hashMap、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。对象可能包含了另外一些对象。在ElasticSearch 中，术语文档有着特定的含义。它是指最顶层或者根对象，这个跟对象被序列化成JSON并存储到ElasticSearch 中，指定了唯一ID.
```

## 2、文档元数据

```
一个文档不仅仅包含它的数据，也包含元数据 -- 有关文档的信息。三个必须的元数据元素如下：
_index 文档在哪存放
_type  文档表示的对象类别
_id    文档唯一标识
```

_index

```
一个索引应该是因共同的特性被分组到一起的文档集合。例如，你可能存储所有的产品在索引 products 中，而存储所有销售的交易到索引 sales 中。虽然也允许存储不相关的数据到一个索引中，但这通常看作是一个反模式的做法。
```

```
tip
	实际上，在 Elasticsearch 中，我们的数据时被存储和索引在 分片 中，而一个索引仅仅是逻辑上的命名空间，这个命名空间由一个或者多个分片组合在一起。然而，这是一个内部细节，我们的应用程序根本不应该关心分片，对于应用程序而言，只需要知道文档位于一个索引内。ElasticSearch 会处理所有的细节。
	
我们将在索引管理介绍如何自行创建和管理索引，但现在我们将让 ElasticSearch帮我们创建索引。所有需要我们做的就是选择一个索引名，这个名字必须小写，不能以下划线开头，不能包含逗号。
```

_type

```
数据可能在索引中只是松散的组合在一起，但是通常明确定义一些数据中的子分区是很有用的。例如，所有的产品都放在一个索引中，但是你有许多不同的产品类别。

这些文档共享一种相同的(或非常相似)的模式。

Elasticsearch 公开了一个称为 types (类型)的特性，他允许您在索引中对数据进行逻辑分区。不同types 的文档可能有不同的字段，但最好能够非常相似。

一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号，并且长度限制为256个字符。
```

_id

```
ID 是一个字符串，当它和 _index 以及 _type 组合就可以唯一确定 elasticsearch 种的一个文档。当你创建一个新的文档，要么提供自己的 _id,要么让 elasticsearch 帮你生成
```

其他元数据

```
还有一些其他的元数据，他们在类型和映射进行了介绍。通过前面已经列出的元数据元素，我们已经能存储文档到 Elasticsearch 中并通过 ID 检索它--换句话说，使用 Elasticsearch 作为文档的存储介质。
```

## 3、索引文档

```
通过使用 index API, 文档可以被索引 -- 存储和使用文档可被搜索。但是首先，我们要确定文档的位置。正如我们刚刚讨论的，一个文档的 _index、_type、_id 唯一标识一个文档。我们可以提供自定义的 _id 值，或者让 indeAPI 自动生成。
```

### 使用自定义的 ID 

```
如果你的文档有一个自然的标识符(例如，一个 user_account 字段或其他标识文档的值)，你应该使用如下方式的 indexAPI 并提供你自己的 _id  :
```

```
PUT /{index}/{type}/{id}
{
"field" : "value",
...
}
```

例子

```
PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "Just trying this out...",
  "date":  "2014/01/01"
}

elasticsearch 响应体如下所示：
{
   "_index":    "website",
   "_type":     "blog",
   "_id":       "123",
   "_version":  1,
   "created":   true
}

该响应表明文档已经成功创建，该索引包括 _index 、 _type 和 _id 元数据， 以及一个新元素： _version 。

在 elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时(包括删除)，_version 的值会递增。在处理冲突中，我们讨论了怎样使用 _version 号码确保你的应用程序中的一部分修改不会覆盖另一部分所做的修改。
```



### Autogenerating IDs

```
如果你的数据没有自然的 ID, elasticsearch 可以帮我们自动生成ID。请求的结构调整为： 不再使用 PUT 谓词(使用这个URL存储这个文档)，而是使用 POST 谓词
```

```
现在 URL 只需要包含 _index 和 _type

POST /website/blog/
{
  "title": "My second blog entry",
  "text":  "Still trying this out...",
  "date":  "2014/01/01"
}

除了 _id 是 elasticsearch 自动生成的，响应的其他部分和前面类似：
响应

{
   "_index":    "website",
   "_type":     "blog",
   "_id":       "AVFgSgVHUP18jI2wRx0w",
   "_version":  1,
   "created":   true
}
```

```
自动生成的 ID 是 URL-safe、 基于 Base64 编码且长度为 20 个字符的 GUID 字符串。这些 GUID 字符串可修改的 FlakeID 模式生成，这种模式允许多个节点并行生成唯一 ID,且互相之间的冲突概率几乎为零。
```



## 4、取回一个文档

```
为了从 elasticsearch 中检索出文档，我们仍然使用相同的 _index, _type, _id , 但是 HTTP 谓词更改为 get 

GET /website/blog/123?pretty
```

```
响应体包括目前已经熟悉了的元数据元素，再加上 _source 字段，这个字段包括我们索引数据时发送给 elasticsearch 的原始 JSON 文档：

{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 1,
  "found" :    true,
  "_source" :  {
      "title": "My first blog entry",
      "text":  "Just trying this out...",
      "date":  "2014/01/01"
  }
}
```

```
在请求的查询字符串参数中加上 pretty 参数，正如前面的例子中看到的，这将会调用 elasticsearch 的 pretty-print 功能，该功能使得 JSON 响应体更加可读。但是，_source 字段不能被格式化打印出来。相反，我们得到的 _source 子弹中的 JSON 串，刚好是和我们传给它的一样.

就是会将其格式化为 更加可读的形式
```



```
GET 请求的响应体包括 {"found":true}, 这证实了文档已经被找到。
如果我们请求一个不存在的文档，我们仍然会得到一个 JSON 响应体，但是 found 将会是 false. 此外， HTTP 响应码将会是 404 Not found, 而不是 200 OK


GET http://localhost:9200/website/blog/124?pretty

{
  "_index" : "website",
  "_type" :  "blog",
  "_id" :    "124",
  "found" :  false
}
```

### 返回文档的一部分

```
默认情况下， get 请求会返回整个文档，这个文档正如存储在 _source 字段中的一样。但是也许你只对其中的 title 字段感兴趣。单个字段能用 _source 参数请求得到，多个字段也能使用逗号分隔的列表来指定。

GET /website/blog/123?_source=title,text

该 _source 字段现在包含的只是我们请求的那些字段，并且已经将 date 字段过滤掉了。

{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 1,
  "found" :   true,
  "_source" : {
      "title": "My first blog entry" ,
      "text":  "Just trying this out..."
  }
}
```

```
或者，如果你只想得到 _source 字段，不需要任何元数据，你能使用 _source 端点：

GET /website/blog/123/_source

{
   "title": "My first blog entry",
   "text":  "Just trying this out...",
   "date":  "2014/01/01"
}
```



## 5、检查文档是否存在

```
如果只想检查一个文档是否存在 —— 根本不想关心内容 --那么用 HEAD 方法来代替 GET 方法。 HEAD 请求没有返回体，只返回一个 HTTP 请求报头：

HEAD http://localhost:9200/website/blog/123

如果文档存在，Elasticsearch 将返回一个 200 ok 的状态码。

HTTP/1.1 200 OK
Content-Type: text/plain; charset=UTF-8
Content-Length: 0


若文档不存在， elasticsearch 将返回一个 404 Not Found 的状态码：

HTTP/1.1 404 Not Found
Content-Type: text/plain; charset=UTF-8
Content-Length: 0
```

当然，一个文档仅仅是在检查的时候不存在，并不意味着一毫秒之后它也不存在：也许同时正好另一个进程就创建了该文档。



## 6、更新整个文档

```
在 elasticsearch 中文档是 不可改变的，不能修改它们。相反，如果想要更新现有的文档，需要重建索引或者进行替换，我们可以使用相同的 indexAPI 进行实现。
```

```
PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "I am starting to get the hang of this...",
  "date":  "2014/01/02"
}

在响应体中，我们能看到 Elasticsearch 已经增加了 _version 字段值：
{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 2,
  "created":   false 
}

created 标志设置成 false ，是因为相同的索引、类型和 ID 的文档已经存在。
```

```
在内部，elasticsearch 已将旧文档标记为已删除，并增加一个全新的文档。尽管你不能再对旧版本的文档进行访问，但它并不会立即消失。当继续索引更多的数据， elasticsearch 会在后台清理这些已删除的文档。
```

```
在本章的后面部分，我们会介绍 update API，这个API 可以用于 partial updates to a document. 虽然它似乎对文档直接进行了修改，但实际上 elasticsearch 按前述完全相同方式执行以下过程：

1、从旧文档构建 JSON
2、更改该 JSON
3、删除旧文档
4、索引一个新文档

唯一的区别在于,  update API 仅仅通过一个客户端请求来实现这些步骤，而不需要单独的 get 和 index 请求。
```

## 7、创建新文档

```
当我们索引一个文档，怎么确认我们正在创建一个完全新的文档，而不是覆盖现有的呢？

请记住，_index _type _id 的组合可以唯一标识一个文档。所以，确保创建一个新文档的最简单办法就是，使用索引请求的 post 形式让 elasticsearch 自动生成唯一 _id：

POST /website/blog/
{ ... }
```

```
然而，如果已经有自己的 _id,那么我们必须告诉 elasticsearch，只有在相同的 _index _type _id 不存在时才接受我们的索引请求。这里有两种方式，他们做的实际是相同的事情。使用哪种，取决于哪种使用起来更方便。
```

```
第一种方法使用 op_type 查询 - 字符串参数：
PUT /website/blog/123?op_type=create
{ ... }

第二种是在 URL 末端使用 /_create 
PUT /website/blog/123/_create
{ ... }
```

```
如果创建新文档的请求成功执行， elasticsearch 会返回元数据和一个 201 created 的 HTTP 响应码。

另一方面，如果具有相同的 _index _type _id 的文档已经存在， elasticsearch  将会返回 409 conflict 响应码，以及如下的错误信息： 



{
   "error": {
      "root_cause": [
         {
            "type": "document_already_exists_exception",
            "reason": "[blog][123]: document already exists",
            "shard": "0",
            "index": "website"
         }
      ],
      "type": "document_already_exists_exception",
      "reason": "[blog][123]: document already exists",
      "shard": "0",
      "index": "website"
   },
   "status": 409
}
```



## 8、删除文档

```
删除文档的语法和我们所知道的规则相同，只是使用 DELETE 方法

DELETE /website/blog/123

如果找到该文档，elasticsearch  将要返回一个 200 OK 的HTTP 响应码，和一个类似以下结构的响应体。注意，字段  _version 值已经增加： 

{
  "found" :    true,
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 3
}

如果文档没有 找到，我们将得到 404 Not Found 的响应码和类似这样的响应体：
{
  "found" :    false,
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 4
}
```

```
即使文档不存在 (Found 是 false), _version 值仍然会增加。这是 elasticsearch 内部记录本的一部分，用来确保这些改变在跨多节点时以正确的顺序执行。
```

```
正如已经在 更新整个文档 中提到，删除文档不会立即将文档从磁盘中删除，只是将文档标记为已删除状态。随着你不断的索引更多的数据， elasticsearch 将会在后台清理标记为已删除的文档。
```



## 9、处理冲突



```
在数据库领域中，有两种方法通常被用来确保并发更新时变更不会丢失：

悲观并发控制
这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此阻塞访问资源以防止冲突。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。


乐观并发控制
Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，如果源数据在读写当中被修改，更新将会失败。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。
```

## 10、乐观并发控制

```
elasticsearch 是分布式的。当文档创建、更新或删除时，新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许 顺序是乱的 。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。


当我们之前讨论 index ， GET 和 delete 请求时，我们指出每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。

我们可以利用 _version 号来确保 应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version 号来达到这个目的。 如果该版本不是当前版本号，我们的请求将会失败。
```

```
1.7以后的 es 不用 version 了 而是使用 if_seq_no 和 if_primary_term 来控制版本

这里就不详细记录了
```

## 11、文档的部分更新



### 更新和冲突

```
在本节的介绍中，我们说明 检索 和 重建索引 步骤的间隔越小，变更冲突的机会越小。 但是它并不能完全消除冲突的可能性。 还是有可能在 update 设法重新索引之前，来自另一进程的请求修改了文档
```



# 2、分布式文档存储

## 1、路由一个文档到一个分片中

```
当索引一个文档的时候，文档会被存储到一个主分片中。elasticsearch 如何知道一个文档应该存放到哪个分片中呢？ 当我们创建文档时，它如何决定这个文档应当被存储在分片1还是分片2中呢？
```

```
是根据下面的公式来的

shard = hash(routing) % number_of_primary_shards

routing 是一个可变值，默认是文档的 _id,也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards (主分片的数量)后得余数。这个分布在 0 到 number_of_primary_shard-1  之间的余数，就是我们所寻求的文档所在分片的位置。
```

```
这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
```

```
所有的文档API (get、index、delete、bulk、update、mget)都接受一个叫做 routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路有参数可以用来确保所有相关文档 -- 例如所有属于同一个用户的文档 -- 都被存储到同一个分片中。
```





# 3、搜索

## 1、空搜索

```
搜索API的最基础的形式是没有指定任何查询的空搜索 ，它简单地返回集群中所有索引下的所有文档：

GET /_search

返回的结果如下

{
   "hits" : {
      "total" :       14,
      "hits" : [
        {
          "_index":   "us",
          "_type":    "tweet",
          "_id":      "7",
          "_score":   1,
          "_source": {
             "date":    "2014-09-17",
             "name":    "John Smith",
             "tweet":   "The Query DSL is really powerful and flexible",
             "user_id": 2
          }
       },
        ... 9 RESULTS REMOVED ...
      ],
      "max_score" :   1
   },
   "took" :           4,
   "_shards" : {
      "failed" :      0,
      "successful" :  10,
      "total" :       10
   },
   "timed_out" :      false
}
```

```
hits

返回结果中最重要的部分是 hits, 它包含 total 字段来表示匹配到的文档总数，并且一个 hits 数组包含所查询结果的前十个文档。

在 hits 数组中每个结果包含文档的 _index 、 _type 、 _id ，加上 _source 字段。这意味着我们可以直接从返回的搜索结果中使用整个文档。这不像其他的搜索引擎，仅仅返回文档的ID，需要你单独去获取文档。

每个结果还有一个 _score ，它衡量了文档与查询的匹配程度。默认情况下，首先返回最相关的文档结果，就是说，返回的文档是按照 _score 降序排列的。在这个例子中，我们没有指定任何查询，故所有的文档具有相同的相关性，因此对所有的结果而言 1 是中性的 _score 。

max_score 值是与查询所匹配文档的 _score 的最大值。
```

```
took
took 值告诉我们执行整个搜索请求耗费了多少毫秒。
```

```
shards
_shards 部分 告诉我们在查询中参与分片的总数，以及这些分片成功了多少个失败了多少个。正常情况下我们不希望分片失败，但是分片失败是可能发生的。如果我们遭遇到一种灾难级别的故障，在这个故障中丢失了相同分片的原始数据和副本，那么对这个分片将没有可用副本来对搜索请求作出响应。假若这样，Elasticsearch 将报告这个分片是失败的，但是会继续返回剩余分片的结果。
```

```
timeout
timed_out 值告诉我们查询是否超时。默认情况下，搜索请求不会超时。 如果低响应时间比完成结果更重要，你可以指定 timeout 为 10 或者 10ms（10毫秒），或者 1s（1秒）：


GET /_search?timeout=10ms

在请求超时之前，Elasticsearch 将会返回已经成功从每个分片获取的结果


应当注意的是 timeout 不是停止执行查询，它仅仅是告知正在协调的节点返回到目前为止收集的结果并且关闭连接。在后台，其他的分片可能仍在执行查询即使是结果已经被发送了。

使用超时是因为 SLA(服务等级协议)对你是很重要的，而不是因为想去中止长时间运行的查询。
```

## 2、多索引，多类型

```
如果不对某一特殊的索引或者类型做限制，就会搜索集群中的所有文档。Elasticsearch 转发搜索请求到每一个主分片或者副本分片，汇集查询出的前10个结果，并且返回给我们。

然而，经常的情况下，你 想在一个或多个特殊的索引并且在一个或者多个特殊的类型中进行搜索。我们可以通过在URL中指定特殊的索引和类型达到这种效果，如下所示：
```

```
/_search 
	在所有索引中搜索所有的类型
	
/gd/_search 
	在 gb 索引中搜索所有的类型

/gd,us/_search
	在 gb 和 us 索引中搜索所有的文档
	
/g*,u*/_search
在任何以 g 或者 u 开头的索引中搜索所有的类型

 /gb/user/_search
在 gb 索引中搜索 user 类型

/gb,us/user,tweet/_search
在 gb 和 us 索引中搜索 user 和 tweet 类型

/_all/user,tweet/_search
在所有的索引中搜索 user 和 tweet 类型
```

```
当在单一的索引下进行搜索的时候，Elasticsearch 转发请求到索引的每个分片中，可以是主分片也可以是副本分片，然后从每个分片中收集结果。多索引搜索恰好也是用相同的方式工作的--只是会涉及到更多的分片。

搜索一个索引有五个主分片和搜索五个索引各有一个分片准确来所说是等价的。
```

## 3、分页

```
在之前的 空搜索 中说明了集群中有 14 个文档匹配了（empty）query 。 但是在 hits 数组中只有 10 个文档。如何才能看到其他的文档？

和 SQL 使用 LIMIT 关键字返回单个 page 结果的方法相同，Elasticsearch 接受 from 和 size 参数：

size 
	显示应该返回的结果数量，默认是 10
from
	显示应该跳过的初始结果数量，默认是 0
```

如果每页展示 5 条结果，可以用下面方式请求得到 1 到 3 页的结果：

```
GET /_search?size=5
GET /_search?size=5&from=5
GET /_search?size=5&from=10
```

```
考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的。
```

```
在分布式系统中深度分页

理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。

现在假设我们请求第 1000 页--结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。

可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。
```

## 4、轻量搜索

```
有两种形式的 搜索 API：一种是 “轻量的” 查询字符串 版本，要求在查询字符串中传递所有的 参数，

另一种是更完整的 请求体 版本，要求使用 JSON 格式和更丰富的查询表达式作为搜索语言。
```

```
查询字符串搜索非常适用于通过命令行做即席查询。例如，查询在 tweet 类型中 a 字段包含 elasticsearch 单词的所有文档：

GET /_all/tweet/_search?q=a:elasticsearch
```

```
下一个查询在 name 字段中包含 john 并且在 tweet 字段中包含 mary 的文档。实际的查询就是这样

+name:john +tweet:mary

但是查询字符串参数所需要的 百分比编码 （译者注：URL编码）实际上更加难懂：
GET /_search?q=%2Bname%3Ajohn+%2Btweet%3Amary


+ 前缀表示必须与查询条件匹配。
类似的， - 前缀表示一定不与查询条件匹配。

没有+ 或者 - 的所有条件都是可选的 -- 匹配的越多，文档就越相关。
```

### _all字段

```
这个简单返回包含 mary 的所有文档：
GET /_search?q=mary
```

```
之前的例子中，我们在 tweet 和 name 字段中搜索内容。然而，这个查询的结果在三个地方提到了 mary ：

有一个用户叫做 Mary
6条微博发自 Mary
一条微博直接 @mary
Elasticsearch 是如何在三个不同的字段中查找到结果的呢？

当索引一个文档的时候，Elasticsearch 取出所有字段的值拼接成一个大的字符串，作为 _all 字段进行索引。例如，当索引这个文档时：
{
    "tweet":    "However did I manage before Elasticsearch?",
    "date":     "2014-09-14",
    "name":     "Mary Jones",
    "user_id":  1
}

这就好似增加了一个名叫 _all 的额外字段：
"However did I manage before Elasticsearch? 2014-09-14 Mary Jones 1"
```

```
除非设置特定字段，否则查询字符串就使用 _all 字段进行搜索

在刚开始开发一个应用时，_all 字段是一个很实用的特性。之后，你会发现如果搜索时用指定字段来代替 _all 字段，将会更好控制搜索结果。当 _all 字段不再有用的时候，可以将它置为失效，正如在 元数据: _all 字段 中所解释的。
```

### 更复杂的查询

```
下面的查询针对 tweets 类型，并使用一下的条件：
name 字段中包含 mary 或者 john
data 值大于 2014-09-10
_all 字段包含 aggregations 或者 geo
```

```
+name:(mary john) +date:>2014-09-10 +(aggregations geo)

查询字符串在做了适当的编码后，可读性很差：

?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo)
```

```
从之前的例子中可以看出，这种 轻量 的查询字符串搜索效果还是挺让人惊喜的。 它的查询语法在相关参考文档中有详细解释，以便简洁的表达很复杂的查询。对于通过命令做一次性查询，或者是在开发阶段，都非常方便。

但同时也可以看到，这种精简让调试更加晦涩和困难。而且很脆弱，一些查询字符串中很小的语法错误，像 - ， : ， / 或者 " 不匹配等，将会返回错误而不是搜索结果。

最后，查询字符串搜索允许任何用户在索引的任意字段上执行可能较慢且重量级的查询，这可能会暴露隐私信息，甚至将集群拖垮。

因为这些原因，不推荐直接向用户暴露查询字符串搜索功能，除非对于集群和数据来说非常信任他们。

相反，我们经常在生产环境中更多地使用功能全面的 request body 查询API，除了能完成以上所有功能，还有一些附加功能。但在到达那个阶段之前，首先需要了解数据在 Elasticsearch 中是如何被索引的。
```



# 4、映射和分析

```
当摆弄索引里面的数据时，我们发现一些奇怪的事情。一些事情看起来被打乱了：在我们的索引中有12条推文，其中只有一条包含日期 2014-09-15 ，但是看一看下面查询命中的 总数 （total）：

GET /_search?q=2014              # 12 results
GET /_search?q=2014-09-15        # 12 results !
GET /_search?q=date:2014-09-15   # 1  result
GET /_search?q=date:2014         # 0  results !
```

```
为什么在 _all 字段查询日期返回所有推文，而在 date 字段只查询年份却没有返回结果？为什么我们在 _all 字段和 date 字段的查询结果有差别？

推测起来，这是因为数据在 _all 字段与 date 字段的索引方式不同。所以，通过请求 gb 索引中 tweet 类型的_映射_（或模式定义），让我们看一看 Elasticsearch 是如何解释我们文档结构的：
```

```json
GET /gb/_mapping


{
    "megacorp": {
        "mappings": {
            "properties": {
                "about": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "age": {
                    "type": "long"
                },
                "first_name": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "interests": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    },
                    "fielddata": true
                },
                "last_name": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "properties": {
                    "properties": {
                        "interests": {
                            "properties": {
                                "fielddata": {
                                    "type": "boolean"
                                },
                                "type": {
                                    "type": "text",
                                    "fields": {
                                        "keyword": {
                                            "type": "keyword",
                                            "ignore_above": 256
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "tags": {
                    "type": "text",
                    "fielddata": true
                }
            }
        }
    }
}
```

```
基于对字段类型的猜测， Elasticsearch 动态为我们产生了一个映射。这个响应告诉我们 date 字段被认为是 date 类型的。由于 _all 是默认字段，所以没有提及它。但是我们知道 _all 字段是 string 类型的。

所以 date 字段和 string 字段 索引方式不同，因此搜索结果也不一样。这完全不令人吃惊。你可能会认为 核心数据类型 strings、numbers、Booleans 和 dates 的索引方式有稍许不同。没错，他们确实稍有不同。

但是，到目前为止，最大的差异在于 代表 精确值 （它包括 string 字段）的字段和代表 全文 的字段。这个区别非常重要——它将搜索引擎和所有其他数据库区别开来。
```



## 1、精确值VS全文

```
elasticsearch 中的数据可以概括的分为两类：精确值和全文。
```

```
精确值如它们听起来那样精确。例如日期或者用户 ID，但字符串也可以表示精确值，例如用户名或邮箱地址。对于精确值来讲，Foo 和 foo 是不同的，2014 和 2014-09-15 也是不同的。

另一方面，全文 是指文本数据（通常以人类容易识别的语言书写），例如一个推文的内容或一封邮件的内容。

全文通常是指非结构化的数据，但这里有一个误解：自然语言是高度结构化的。问题在于自然语言的规则是复杂的，导致计算机难以正确解析。例如，考虑这条语句：

May is fun but June bores me.
它指的是月份还是人？
```

```
精确值很容易查询。结果是二进制的： 要么匹配查询，要么不匹配。
这种查询很容易用 SQL 表示：
WHERE name    = "John Smith"
  AND user_id = 2
  AND date    > "2014-09-15"
```

```
我们很少对全文类型的域做精确匹配。相反，我们希望在文本类型的域中搜索。不仅如此，我们还希望搜索能够理解我们的 意图 ：

搜索 UK ，会返回包含 United Kindom 的文档。
搜索 jump ，会匹配 jumped ， jumps ， jumping ，甚至是 leap 。
搜索 johnny walker 会匹配 Johnnie Walker ， johnnie depp 应该匹配 Johnny Depp 。
fox news hunting 应该返回福克斯新闻（ Foxs News ）中关于狩猎的故事，同时， fox hunting news 应该返回关于猎狐的故事。
为了促进这类在全文域中的查询，Elasticsearch 首先 分析 文档，之后根据结果创建 倒排索引 。在接下来的两节，我们会讨论倒排索引和分析过程。
```

## 2、倒排索引

```
elasticsearch 使用一种称为 倒排索引的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。
```

例如，假设我们有两个文档，每个文档的 `content` 域包含如下内容：

1. The quick brown fox jumped over the lazy dog
2. Quick brown foxes leap over lazy dogs in summer

```
为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 词（我们称它为 词条 或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：
```

```
Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------
```

```
现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档：

Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
quick   |   X   |
------------------------
Total   |   2   |  1
两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。
```

但是，我们目前的倒排索引有一些问题：

- `Quick` 和 `quick` 以独立的词条出现，然而用户可能认为它们是相同的词。
- `fox` 和 `foxes` 非常相似, 就像 `dog` 和 `dogs` ；他们有相同的词根。
- `jumped` 和 `leap`, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。

使用前面的索引搜索 `+Quick +fox` 不会得到任何匹配文档。（记住，`+` 前缀表明这个词必须存在。）只有同时出现 `Quick` 和 `fox` 的文档才满足这个查询条件，但是第一个文档包含 `quick fox` ，第二个文档包含 `Quick foxes` 。



```
我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。

如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如：

- Quick 可以小写化为 quick 。
- foxes 可以 词干提取 --变为词根的格式-- 为 fox 。类似的， dogs 可以为提取为 dog 。
- jumped 和 leap 是同义词，可以索引为相同的单词 jump 。

现在索引看上去像这样：


Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
dog     |   X   |  X
fox     |   X   |  X
in      |       |  X
jump    |   X   |  X
lazy    |   X   |  X
over    |   X   |  X
quick   |   X   |  X
summer  |       |  X
the     |   X   |  X
------------------------
```

```
这还远远不够。我们搜索 +Quick +fox 仍然 会失败，因为在我们的索引中，已经没有 Quick 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询 +quick +fox ，这样两个文档都会匹配！

这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。

分词和标准化的过程称为 分析 ， 我们会在下个章节讨论。
```

## 3、分析与分析器

```
分析包含下面的过程：
	-首先，将一块文本分成适合于倒排索引的独立的词条。
	-之后，将这些词条统一化为标准格式以提高它们的"可搜索性"，或者recall.
```

```
字符过滤器
	首先，字符串按顺序通过每个字符过滤器。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉 html，或者将 & 转化成 and.
	
分词器
	其次，字符串被分词器分为单个词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。
	
Token 过滤器
	最后，词条按顺序通过每个 token 过滤器。这个过程可能会改变词条(例如，小写花 	Quick),删除词条(例如，像 a, and , the 等无用词)，或者增加词条（例如，像 jump 和 leap 这种同义词）。
```

### 分词器

```
Elasticsearch提供了开箱即用的字符过滤器、分词器和token 过滤器。 这些可以组合起来形成自定义的分析器以用于不同的目的。我们会在 自定义分析器 章节详细讨论。

内置分析器
	但是， Elasticsearch还附带了可以直接使用的预包装的分析器。 接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：

"Set the shape to semi-transparent by calling set_trans(5)"
```

```
标准分析器
	标准分析器是 elasticsearch 默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 unicode联盟 定义的单词边界 划分文本。删除绝大部分标点。最后，将词条小写。它会产生
	
	set, the, shape, to, semi, transparent, by, calling, set_trans, 5
	
	
简单分析器
	简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生
	set, the, shape, to, semi, transparent, by, calling, set, trans
	
空格分析器
	空格分析器在空格的地方划分文本。它会产生
Set, the, shape, to, semi-transparent, by, calling, set_trans(5)

语言分析器
	特定语言分析器可用于很多语言。它们可以考虑指定语言的特点。 英语 分析器附带了一组英语无用词（常用单词，例如 and 或者 the ，它们对相关性没有多少影响），它们会被删除。 由于理解英语语法的规则，这个分词器可以提取英语单词的 词干 。
	
	英语 分词器会产生下面的词条：

set, shape, semi, transpar, call, set_tran, 5
注意看 transparent`、 `calling 和 set_trans 已经变为词根格式。
```

### 什么时候使用分析器

```
当我们索引一个文档，它的全文域被分析成词条以用来创建倒排索引。但是，当我们在全文域搜索的时候，我们需要将查询字符串通过 相同的分析过程，以保证我们搜索的词条格式与索引中的字条格式一致。
```

```
全文查询，理解每个域是如何定义的，因此它们可以做 正确的事：

	-当你查询一个 全文 域时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。
	-当你查询一个 精确值 域时，不会分析查询字符串， 而是搜索你指定的精确值.
```

### 指定分析器

```
当Elasticsearch在你的文档中检测到一个新的字符串域 ，它会自动设置其为一个全文 字符串 域，使用 标准 分析器对它进行分析。

你不希望总是这样。可能你想使用一个不同的分析器，适用于你的数据使用的语言。有时候你想要一个字符串域就是一个字符串域--不使用分析，直接索引你传入的精确值，例如用户ID或者一个内部的状态域或标签。

要做到这一点，我们必须手动指定这些域的映射。
```



## 4、复杂核心域类型

```
除了我们提到的简单标量类型，JSON还有 null 值，数组，和对象，这些 elasticsearch 都是支持的。
```

### 1、多值域

```
很有可能，我们希望 tag 域 包含多个标签。我们可以以数组的形式索引标签：
{ "tag": [ "search", "nosql" ]}

对于数组，没有特殊的映射需求。任何域都可以包含0、1或者多个值，就像全文域分析得到多个词条。

这暗示 数组中所有的值必须是相同数据类型的 。你不能将日期和字符串混在一起。如果你通过索引数组来创建新的域，Elasticsearch 会用数组中第一个值的数据类型作为这个域的 类型 。

当你从 Elasticsearch 得到一个文档，每个数组的顺序和你当初索引文档时一样。你得到的 _source 域，包含与你索引的一模一样的 JSON 文档。

但是，数组是以多值域 索引的—可以搜索，但是无序的。 在搜索的时候，你不能指定 “第一个” 或者 “最后一个”。 更确切的说，把数组想象成 装在袋子里的值 。
```

### 2、空域

```
当然，数组可以为空。这相当于存在零值。事实上，在 Lucene 中是不能存储 null 值的，所以我们认为存在 null 值的域为空域。

下面三种域被认为是空的，它们将不会被索引：

"null_value":               null,
"empty_array":              [],
"array_with_null_value":    [ null ]
```



### 3、多层级对象

```
我们讨论的最后一个 JSON 原生数据类是对象 -- 在其他语言中称为哈希，哈希 map，字典或者关联数组。

内部对象 经常用于 嵌入一个实体或对象到其它对象中。例如，与其在 tweet 文档中包含 user_name 和  user_id 域，我们也可以这样写：

{
    "tweet":            "Elasticsearch is very flexible",
    "user": {
        "id":           "@johnsmith",
        "gender":       "male",
        "age":          26,
        "name": {
            "full":     "John Smith",
            "first":    "John",
            "last":     "Smith"
        }
    }
}
```

```
内部对象的映射编辑
Elasticsearch 会动态 监测新的对象域并映射它们为 对象 ，在  properties 属性下列出内部域：

{
  "gb": {
    "tweet": { 
      "properties": {
        "tweet":            { "type": "string" },
        "user": { 
          "type":             "object",
          "properties": {
            "id":           { "type": "string" },
            "gender":       { "type": "string" },
            "age":          { "type": "long"   },
            "name":   { 
              "type":         "object",
              "properties": {
                "full":     { "type": "string" },
                "first":    { "type": "string" },
                "last":     { "type": "string" }
              }
            }
          }
        }
      }
    }
  }
}


user 和 name 域的映射结构与 tweet 类型的相同。事实上， type 映射只是一种特殊的 对象 映射，我们称之为 根对象 。除了它有一些文档元数据的特殊顶级域，例如 _source 和 _all 域，它和其他对象一样。
```

### 4、内部对象是如何索引的

```
Lucene 不理解内部对象。 Lucene 文档是由一组键值对列表组成的。为了能让 Elasticsearch 有效地索引内部类，它把我们的文档转化成这样：

{
    "tweet":            [elasticsearch, flexible, very],
    "user.id":          [@johnsmith],
    "user.gender":      [male],
    "user.age":         [26],
    "user.name.full":   [john, smith],
    "user.name.first":  [john],
    "user.name.last":   [smith]
}

内部域可以通过名称引用(例如，first)。为了区分同名的两个域，我们可以使用全路径()（例如， user.name.first ） 或 type 名加路径（ tweet.user.name.first ）。

在前面简单扁平的文档中，没有 user 和 user.name 域。Lucene 索引只有标量和简单值，没有复杂数据结构。
```

### 5、内部对象数组

```
最后，考虑包含 内部对象的数组是如何被索引的。 假设我们有个 followers 数组：

{
    "followers": [
        { "age": 35, "name": "Mary White"},
        { "age": 26, "name": "Alex Jones"},
        { "age": 19, "name": "Lisa Smith"}
    ]
}
这个文档会像我们之前描述的那样被扁平化处理，结果如下所示：

{
    "followers.age":    [19, 26, 35],
    "followers.name":   [alex, jones, lisa, smith, mary, white]
}

{age: 35} 和 {name: Mary White} 之间的相关性已经丢失了，因为每个多值域只是一包无序的值，而不是有序数组。这足以让我们问，“有一个26岁的追随者？”

但是我们不能得到一个准确的答案：“是否有一个26岁 名字叫 Alex Jones 的追随者？”

相关内部对象被称为 nested 对象，可以回答上面的查询，我们稍后会在嵌套对象中介绍它。
```



# 5、请求体查询

## 1、空查询

```
让我们以最简单的 search API 的形式开启我们的旅程，空查询将返回所有索引库（indices)中的所有文档：

GET /_search
{} 

这是一个空的请求体。

只用一个查询字符串，你就可以在一个、多个或者 _all 索引库（indices）和一个、多个或者所有types中查询：

GET /index_2014*/type1,type2/_search
{}


同时你可以使用 from 和 size 参数来分页：
GET /_search
{
  "from": 30,
  "size": 10
}

相对于使用晦涩难懂的查询字符串的方式，一个带请求体的查询允许我们使用 查询领域特定语言（query domain-specific language）  Query DSL 来写查询语句。
```



## 2、查询表达式

```
查询表达式(query dsl)是一种非常灵活又富有表现力的查询语言。 elasticsearch 使用它可以以简单的 JSON 接口来展示 Lucene 功能的绝大部分。在你的应用中，你应该用它来编写你的查询语句。它可以使你的查询语句更灵活、更精确、易读和易调试
```

```
要使用这种查询表达式，只需将查询语句传递给 query 参数：

GET /_search
{
    "query": YOUR_QUERY_HERE
}

空查询（empty search） —{}— 在功能上等价于使用 match_all 查询， 正如其名字一样，匹配所有文档：
GET /_search
{
    "query": {
        "match_all": {}
    }
}
```

### 1、查询语句的结构

```
一个查询语句的典型结构

{
    QUERY_NAME: {
        ARGUMENT: VALUE,
        ARGUMENT: VALUE,...
    }
}

如果是针对某个字段，那么它的结构如下：
{
    QUERY_NAME: {
        FIELD_NAME: {
            ARGUMENT: VALUE,
            ARGUMENT: VALUE,...
        }
    }
}

例子：
GET /_search
{
    "query": {
        "match": {
            "tweet": "elasticsearch"
        }
    }
}
```

### 2、合并查询语句

```
查询语句(Query clauses) 就像一些简单的组合块 ，这些组合块可以彼此之间合并组成更复杂的查询。这些语句可以是如下形式：

叶子语句（Leaf clauses） (就像 match 语句) 被用于将查询字符串和一个字段（或者多个字段）对比。
复合(Compound) 语句 主要用于 合并其它查询语句。 比如，一个 bool 语句 允许在你需要的时候组合其它语句，无论是  must 匹配、 must_not 匹配还是 should 匹配，同时它可以包含不评分的过滤器（filters）：

{
    "bool": {
        "must":     { "match": { "tweet": "elasticsearch" }},
        "must_not": { "match": { "name":  "mary" }},
        "should":   { "match": { "tweet": "full text" }},
        "filter":   { "range": { "age" : { "gt" : 30 }} }
    }
}


一条复合语句可以合并 任何 其它查询语句，包括复合语句，了解这一点是很重要的。这就意味着，复合语句之间可以互相嵌套，可以表达非常复杂的逻辑。

一条复合语句可以将多条语句 — 叶子语句和其它复合语句 — 合并成一个单一的查询语句。
```

## 3、查询与过滤

```
filter 这个词表示不评分、只过滤情况下的查询。
```

### 性能差异

```
过滤查询(filtering queries) 只是简单的检查包含或者排除，这就使得计算起来非常快。考虑到至少有一个过滤查询(filtering query)的结果是 “稀少的”（很少匹配的文档），并且经常使用不评分查询（non-scoring queries），结果会被缓存到内存中以便快速读取，所以有各种各样的手段来优化查询结果。


相反，评分查询（scoring queries）不仅仅要找出 匹配的文档，还要计算每个匹配文档的相关性，计算相关性使得它们比不评分查询费力的多。同时，查询结果并不缓存。


多亏倒排索引（inverted index），一个简单的评分查询在匹配少量文档时可能与一个涵盖百万文档的filter表现的一样好，甚至会更好。但是在一般情况下，一个filter 会比一个评分的query性能更优异，并且每次都表现的很稳定。

过滤（filtering）的目标是减少那些需要通过评分查询（scoring queries）进行检查的文档。
```

###  如何选择查询与过滤

通常的规则是，使用 查询（query）语句来进行 *全文* 搜索或者其它任何需要影响 *相关性得分* 的搜索。除此以外的情况都使用过滤（filters)。

## 4、最重要的查询

### match_all

```JSON
{
    "match_all":{}
}

它经常与 filter 结合使用--例如，检索收件箱里的所有邮件。所有邮件被认为具有相同的相关性，所以都将获得分值为 1 的中性 `_score`。
```

### match查询

```
无论你在任何字段上进行的是全文搜索还是精确查询，match 查询是你可用的标准查询。

如果你在一个全文字段上使用 match 查询，在执行查询前，它将用正确的分析器去分析查询字符串。

如果在一个精确值的字段上使用它，例如数字、日期、布尔或者一个 not_analyzed 字符串字段，那么它将会精确匹配给定的值：

{ "match": { "age":    26           }}
{ "match": { "date":   "2014-09-01" }}
{ "match": { "public": true         }}
{ "match": { "tag":    "full_text"  }}

对于精确值的查询，你可能需要使用 filter 语句来取代 query，因为 filter 将会被缓存。接下来，我们将看到一些关于 filter 的例子。
```

```
不像我们在 轻量 搜索 章节介绍的字符串查询（query-string search）， match 查询不使用类似 +user_id:2 +tweet:search 的查询语法。它只是去查找给定的单词。这就意味着将查询字段暴露给你的用户是安全的；你需要控制那些允许被查询字段，不易于抛出语法异常。
```

### multi_match 查询

```
multi_match 查询可以在多个字段上执行相同的 match 查询：
{
    "multi_match": {
        "query":    "full text search",
        "fields":   [ "title", "body" ]
    }
}

这个查询语句意思是 查找 full text search

在 title 和 body 字段里面
```

### range   查询

```

renge 查询找出那些落在指定区间内的数据或者时间：

{
    "range": {
        "age": {
            "gte":  20,
            "lt":   30
        }
    }
}

被允许的操作符如下

gt     greater than
gte   greater than equals
lte  less than  equals
lt  less than  
```

###  term

```
term 查询被用于精确值匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串

{ "term": { "age":    26           }}
{ "term": { "date":   "2014-09-01" }}
{ "term": { "public": true         }}
{ "term": { "tag":    "full_text"  }}

term 查询对于输入的文本不分析，所以它将给定的值进行精确查询
```

### terms

```
terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值的任何一个值，那么这个文档满足条件

{ "terms": { "tag": [ "search", "full_text", "nosql" ] }}


和 term 查询一样，terms 查询对于输入的文本不分析。它查询那些精确匹配的值（包括在大小写、重音、空格等方面的差异）。
```

### exists 查询和missing查询

```
exists 查询和 missing 查询被用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档。这与SQL中的 IS_NULL (missing) 和 NOT IS_NULL (exists) 在本质上具有共性：

miss查询在 elasticsearch7.x的时候已经被删除(Filter Query Missing 已经从 ES 5 版本移除)。


{
    "exists":   {
        "field":    "title"
    }
}

查询 title 字段是否有值

这些查询经常用于某个字段有值的情况和某个字段缺值的情况。
```

[match 和 trem 解析](https://my.oschina.net/wsyblog/blog/710245?utm_medium=referral)

```
{
	"query": {
			"term":{"about":"like"}
	}
}

结果

{
                "_index": "megacorp",
                "_type": "employee",
                "_id": "3",
                "_score": 0.7199211,
                "_source": {
                    "first_name": "Douglas",
                    "last_name": "Fir",
                    "age": 35,
                    "about": "I like to build cabinets",
                    "interests": [
                        "forestry"
                    ]
                }
            }
            
            
 按 term 的意思是精确查询，应该不会分词，如果对于某个字段，想精确匹配，即搜索什么词匹配什么词，类似 sql 中的 = 操作，比如只能通过 I like to build cabinets 搜索到 about, 而不想让 like 和 build 也搜索到，那么，你可以在建立索引阶段指定该字段为"index": "not_analyzed"，此时，elasticsearch将不会对该字段的值进行分词操作，只保留全文字索引。
 
 但是 搜索 about = like 还是搜索到了 这是因为文档存进去的时候 about="I like to build cabinets" 已经被分词过了，分为了 
  i like to build cabinets . 
  
  所有 about = like 还是会被分词。
  
  
 match 查询会先对搜索词进行分词，分词完毕后再逐个对分词结果进行匹配, 因此相比于 term 的精确搜索，match 是分词搜索，match 搜索还有两个相似功能的变种，一个是 match_phrase， 一个是 multi_match
```





## 5、组合多查询

```
现实的查询需求从来都没有那么简单；它们需要在多个字段上查询多种多样的文本，并且根据一系列的标准来过滤。为了构建类似的高级查询，你需要一种能够将多查询组合成单一查询的查询方法。

你可以用 bool 查询来实现你的需求。这种查询将多查询组合在一起，成为用户自己想要的布尔查询。它接收以下参数：

must 
	文档必须匹配这些条件才能被包含进来
	
must_not
	文档必须不匹配这些条件才能被包含进来
	
should
	如果满足这些语句的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。
	就是说里面的查询语句该怎么执行还是怎么执行，should就给它们加了_score
	

filter 
	必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。
	
should 和 filter 一个是增加 score, 一个是去除 score. 里面的查询语句该怎么执行还是怎么执行。
```

```
由于这是我们看到的第一个包含多个查询的查询，所以有必要讨论一下相关性得分是如何组成的。每一个子查询都独自地计算文档的相关性得分。一旦他们的得分被计算出来， bool 查询就将这些得分进行合并并且返回一个代表整个布尔操作的得分。
```

```
tip:
如果没有 must 语句，那么至少需要能够匹配其中的一条 should 语句。但，如果存在至少一条 must 语句，则对 should 语句的匹配没有要求。
```



例子

```json
{
    "bool": {
        "must":     { "match": { "title": "how to make millions" }},
        "must_not": { "match": { "tag":   "spam" }},
        "should": [
            { "match": { "tag": "starred" }},
            { "range": { "date": { "gte": "2014-01-01" }}}
        ]
    }
}


{
    "bool": {
        "must":     { "match": { "title": "how to make millions" }},
        "must_not": { "match": { "tag":   "spam" }},
        "should": [
            { "match": { "tag": "starred" }}
        ],
        "filter": {
          "range": { "date": { "gte": "2014-01-01" }} 
        }
    }
}



{
    "bool": {
        "must":     { "match": { "title": "how to make millions" }},
        "must_not": { "match": { "tag":   "spam" }},
        "should": [
            { "match": { "tag": "starred" }}
        ],
        "filter": {
          "range": { "date": { "gte": "2014-01-01" }} 
        }
    }
}


{
    "bool": {
        "must":     { "match": { "title": "how to make millions" }},
        "must_not": { "match": { "tag":   "spam" }},
        "should": [
            { "match": { "tag": "starred" }}
        ],
        "filter": {
          "bool": { 
              "must": [
                  { "range": { "date": { "gte": "2014-01-01" }}},
                  { "range": { "price": { "lte": 29.99 }}}
              ],
              "must_not": [
                  { "term": { "category": "ebooks" }}
              ]
          }
        }
    }
}
```



### constant_score 查询

```
尽管没有 bool 查询使用这么频繁，constant_score 查询也是你工具箱里有用的查询工具。它将一个不变的常量评分应用于所有匹配的文档。它被经常用于你只需要执行一个 filter 而没有其它查询（例如，评分查询）的情况下。

可以使用它来取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。

{
    "constant_score":   {
        "filter": {
            "term": { "category": "ebooks" } 
        }
    }
}

term 查询被放置在 constant_score 中，转成不评分的 filter。这种方式可以用来取代只有 filter 语句的 bool 查询。
```



## 6、验证查询

```
查询可以变得非常的复杂，尤其和不同的分析器与不同的字段映射结合时，理解起来就有点困难了。不过 validate-query API 可以用来验证查询是否合法。
```

```
GET /gb/tweet/_validate/query
{
   "query": {
      "tweet" : {
         "match" : "really powerful"
      }
   }
}

以上 validate 请求的应答告诉我们这个查询是不合法的：

{
  "valid" :         false,
  "_shards" : {
    "total" :       1,
    "successful" :  1,
    "failed" :      0
  }
}
```

### 理解错误信息

```
为了找出 查询不合法的原因，可以将 explain 参数 加到查询字符串中：

GET /gb/tweet/_validate/query?explain 
{
   "query": {
      "tweet" : {
         "match" : "really powerful"
      }
   }
}

很明显，我们将查询类型(match)与字段名称 (tweet)搞混了：

{
  "valid" :     false,
  "_shards" :   { ... },
  "explanations" : [ {
    "index" :   "gb",
    "valid" :   false,
    "error" :   "org.elasticsearch.index.query.QueryParsingException:
                 [gb] No query registered for [tweet]"
  } ]
}
```

### 理解查询语句



```
对于合法查询，使用 explain 参数将返回可读的描述，这对准确理解 Elasticsearch 是如何解析你的 query 是非常有用的：

GET /_validate/query?explain
{
   "query": {
      "match" : {
         "tweet" : "really powerful"
      }
   }
}

我们查询的每一个 index 都会返回对应的 explanation ，因为每一个 index 都有自己的映射和分析器：
{
  "valid" :         true,
  "_shards" :       { ... },
  "explanations" : [ {
    "index" :       "us",
    "valid" :       true,
    "explanation" : "tweet:really tweet:powerful"
  }, {
    "index" :       "gb",
    "valid" :       true,
    "explanation" : "tweet:realli tweet:power"
  } ]
}

从 explanation 中可以看出，匹配 really powerful 的 match 查询被重写为两个针对 tweet 字段的 single-term 查询，一个single-term查询对应查询字符串分出来的一个term。

当然，对于索引 us ，这两个 term 分别是 really 和 powerful ，而对于索引 gb ，term 则分别是 realli 和 power 。之所以出现这个情况，是由于我们将索引 gb 中 tweet 字段的分析器修改为 english 分析器。
```

# 6、排序与相关性

## 1、排序

```
为了按照相关性来排序，需要将相关性表示为一个数值。在elasticsearch 中，相关性得分由一个浮点数进行表示，并在搜索结果中通过 _sroce 参数返回，默认排序是 _score 降序。
```

```
有时，相关性评分对你来说并没有意义。例如，下面的查询返回所有 user_id 字段包含 1 的结果： 
GET /search 
{
    "query" : {
        "bool" : {
            "filter" : {
                "term" : {
                    "user_id" : 1
                }
            }
        }
    }
}

这里没有一个有意义的分数：因为我们使用的是 filter （过滤），这表明我们只希望获取匹配 user_id: 1 的文档，并没有试图确定这些文档的相关性。 实际上文档将按照随机顺序返回，并且每个文档都会评为零分。
```

```
note
如果评分为零对你造成了困扰，你可以使用 constant_score 查询进行替代：
GET /_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "term" : {
                    "user_id" : 1
                }
            }
        }
    }
}

这将让所有文档应用一个恒定分数（默认为 1 ）。它将执行与前述查询相同的查询，并且所有的文档将像之前一样随机返回，这些文档只是有了一个分数而不是零分。
```

### 按照字段的值排序

```
在这个案例中，通过时间来对 tweets 进行排序是有意义的，最新的 twees 排在最前。我们可以使用 sort 参数进行实现。

GET /_search
{
    "query" : {
        "bool" : {
            "filter" : { "term" : { "user_id" : 1 }}
        }
    },
    "sort": { "date": { "order": "desc" }}
}


你会注意到结果中的两个不同点：

"hits" : {
    "total" :           6,
    "max_score" :       null, 
    "hits" : [ {
        "_index" :      "us",
        "_type" :       "tweet",
        "_id" :         "14",
        "_score" :      null, 
        "_source" :     {
             "date":    "2014-09-24",
             ...
        },
        "sort" :        [ 1411516800000 ] 
    },
    ...
}
 

_score 不被计算, 因为它并没有用于排序。

你可以使用  
 "sort": { "_score": { "order": "desc" }}
来使 _score 应用于排序


date 字段的值表示为自 epoch (January 1, 1970 00:00:00 UTC)以来的毫秒数，通过 sort 字段的值进行返回。


还有一种简便的写法，你可以指定一个或多个字段用来排序

 "sort": "number_of_children"
 "sort": ["number_of_children1", "number_of_children2"]
  
 字段将会默认升序排序，而按照 _score 的值进行降序排序 
```

### 多级排序

````
假定我们想要结合使用 date 和 _score 进行查询，并且匹配的结果首先按照日期排序，然后按照相关性排序。

GET /_search
{
    "query" : {
        "bool" : {
            "must":   { "match": { "tweet": "manage text search" }},
            "filter" : { "term" : { "user_id" : 2 }}
        }
    },
    "sort": [
        { "date":   { "order": "desc" }},
        { "_score": { "order": "desc" }}
    ]
}

排序条件的顺序是很重要的。结果首先按第一个条件排序，仅当结果集的第一个 sort 值完全相同时才会按照第二个条件进行排序，以此类推。

多级排序并不一定包含 _score 。你可以根据一些不同的字段进行排序， 如地理距离或是脚本计算的特定值。
```

```
note 

Query-string 搜索 也支持自定义排序，可以在查询字符串中使用 sort 参数：

GET /_search?sort=date:desc&sort=_score&q=search
```

### 多值字段的排序

```
一种情形是字段有多个值的排序， 需要记住这些值并没有固有的顺序；一个多值的字段仅仅是多个值的包装，这时应该选择哪个进行排序呢？

对于数字或日期，你可以将多值字段减为单值，这可以通过使用 min 、 max 、 avg 或是 sum 排序模式 。 例如你可以按照每个 date 字段中的最早日期进行排序，通过以下方法：

"sort": {
    "dates": {
        "order": "asc",
        "mode":  "min"
    }
}
```



[浅析elasticsearch Doc Values](https://cloud.tencent.com/developer/article/1463890)





























