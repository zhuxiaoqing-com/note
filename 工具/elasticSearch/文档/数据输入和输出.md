## 7.x 的新特性（该笔记基于2.x版本）

```
去除了 type 

1.7以后的 es 不用 version 了 而是使用 if_seq_no 和 if_primary_term 来控制版本

_mapping  去除了映射 type 7.x已经没有type的概念了。

```

# 1、数据输入和输出

## 1、什么是文档

```
在大多数应用中，多数实体或对象可以被序列化为包含键值对的 JSON 对象。一个键可以是一个字段或字段的名称，
一个值可以是一个字符串，一个数字，一个布尔值，另一个对象，一些数组值，或一些其他特殊类型诸如表示日期的字符串，或代表一个地理位置的对象
```

```
通常情况下，我们使用的术语对象和文档是可以互相替换的。不过，有一个区别：一个对象仅仅是类似于 hash、hashMap、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。对象可能包含了另外一些对象。在ElasticSearch 中，术语文档有着特定的含义。它是指最顶层或者根对象，这个跟对象被序列化成JSON并存储到ElasticSearch 中，指定了唯一ID.
```

## 2、文档元数据

```
一个文档不仅仅包含它的数据，也包含元数据 -- 有关文档的信息。三个必须的元数据元素如下：
_index 文档在哪存放
_type  文档表示的对象类别
_id    文档唯一标识
```

_index

```
一个索引应该是因共同的特性被分组到一起的文档集合。例如，你可能存储所有的产品在索引 products 中，而存储所有销售的交易到索引 sales 中。虽然也允许存储不相关的数据到一个索引中，但这通常看作是一个反模式的做法。
```

```
tip
	实际上，在 Elasticsearch 中，我们的数据时被存储和索引在 分片 中，而一个索引仅仅是逻辑上的命名空间，这个命名空间由一个或者多个分片组合在一起。然而，这是一个内部细节，我们的应用程序根本不应该关心分片，对于应用程序而言，只需要知道文档位于一个索引内。ElasticSearch 会处理所有的细节。
	
我们将在索引管理介绍如何自行创建和管理索引，但现在我们将让 ElasticSearch帮我们创建索引。所有需要我们做的就是选择一个索引名，这个名字必须小写，不能以下划线开头，不能包含逗号。
```

_type

```
数据可能在索引中只是松散的组合在一起，但是通常明确定义一些数据中的子分区是很有用的。例如，所有的产品都放在一个索引中，但是你有许多不同的产品类别。

这些文档共享一种相同的(或非常相似)的模式。

Elasticsearch 公开了一个称为 types (类型)的特性，他允许您在索引中对数据进行逻辑分区。不同types 的文档可能有不同的字段，但最好能够非常相似。

一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号，并且长度限制为256个字符。
```

_id

```
ID 是一个字符串，当它和 _index 以及 _type 组合就可以唯一确定 elasticsearch 种的一个文档。当你创建一个新的文档，要么提供自己的 _id,要么让 elasticsearch 帮你生成
```

其他元数据

```
还有一些其他的元数据，他们在类型和映射进行了介绍。通过前面已经列出的元数据元素，我们已经能存储文档到 Elasticsearch 中并通过 ID 检索它--换句话说，使用 Elasticsearch 作为文档的存储介质。
```

## 3、索引文档

```
通过使用 index API, 文档可以被索引 -- 存储和使用文档可被搜索。但是首先，我们要确定文档的位置。正如我们刚刚讨论的，一个文档的 _index、_type、_id 唯一标识一个文档。我们可以提供自定义的 _id 值，或者让 indeAPI 自动生成。
```

### 使用自定义的 ID 

```
如果你的文档有一个自然的标识符(例如，一个 user_account 字段或其他标识文档的值)，你应该使用如下方式的 indexAPI 并提供你自己的 _id  :
```

```
PUT /{index}/{type}/{id}
{
"field" : "value",
...
}
```

例子

```
PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "Just trying this out...",
  "date":  "2014/01/01"
}

elasticsearch 响应体如下所示：
{
   "_index":    "website",
   "_type":     "blog",
   "_id":       "123",
   "_version":  1,
   "created":   true
}

该响应表明文档已经成功创建，该索引包括 _index 、 _type 和 _id 元数据， 以及一个新元素： _version 。

在 elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时(包括删除)，_version 的值会递增。在处理冲突中，我们讨论了怎样使用 _version 号码确保你的应用程序中的一部分修改不会覆盖另一部分所做的修改。
```



### Autogenerating IDs

```
如果你的数据没有自然的 ID, elasticsearch 可以帮我们自动生成ID。请求的结构调整为： 不再使用 PUT 谓词(使用这个URL存储这个文档)，而是使用 POST 谓词
```

```
现在 URL 只需要包含 _index 和 _type

POST /website/blog/
{
  "title": "My second blog entry",
  "text":  "Still trying this out...",
  "date":  "2014/01/01"
}

除了 _id 是 elasticsearch 自动生成的，响应的其他部分和前面类似：
响应

{
   "_index":    "website",
   "_type":     "blog",
   "_id":       "AVFgSgVHUP18jI2wRx0w",
   "_version":  1,
   "created":   true
}
```

```
自动生成的 ID 是 URL-safe、 基于 Base64 编码且长度为 20 个字符的 GUID 字符串。这些 GUID 字符串可修改的 FlakeID 模式生成，这种模式允许多个节点并行生成唯一 ID,且互相之间的冲突概率几乎为零。
```



## 4、取回一个文档

```
为了从 elasticsearch 中检索出文档，我们仍然使用相同的 _index, _type, _id , 但是 HTTP 谓词更改为 get 

GET /website/blog/123?pretty
```

```
响应体包括目前已经熟悉了的元数据元素，再加上 _source 字段，这个字段包括我们索引数据时发送给 elasticsearch 的原始 JSON 文档：

{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 1,
  "found" :    true,
  "_source" :  {
      "title": "My first blog entry",
      "text":  "Just trying this out...",
      "date":  "2014/01/01"
  }
}
```

```
在请求的查询字符串参数中加上 pretty 参数，正如前面的例子中看到的，这将会调用 elasticsearch 的 pretty-print 功能，该功能使得 JSON 响应体更加可读。但是，_source 字段不能被格式化打印出来。相反，我们得到的 _source 子弹中的 JSON 串，刚好是和我们传给它的一样.

就是会将其格式化为 更加可读的形式
```



```
GET 请求的响应体包括 {"found":true}, 这证实了文档已经被找到。
如果我们请求一个不存在的文档，我们仍然会得到一个 JSON 响应体，但是 found 将会是 false. 此外， HTTP 响应码将会是 404 Not found, 而不是 200 OK


GET http://localhost:9200/website/blog/124?pretty

{
  "_index" : "website",
  "_type" :  "blog",
  "_id" :    "124",
  "found" :  false
}
```

### 返回文档的一部分

```
默认情况下， get 请求会返回整个文档，这个文档正如存储在 _source 字段中的一样。但是也许你只对其中的 title 字段感兴趣。单个字段能用 _source 参数请求得到，多个字段也能使用逗号分隔的列表来指定。

GET /website/blog/123?_source=title,text

该 _source 字段现在包含的只是我们请求的那些字段，并且已经将 date 字段过滤掉了。

{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 1,
  "found" :   true,
  "_source" : {
      "title": "My first blog entry" ,
      "text":  "Just trying this out..."
  }
}
```

```
或者，如果你只想得到 _source 字段，不需要任何元数据，你能使用 _source 端点：

GET /website/blog/123/_source

{
   "title": "My first blog entry",
   "text":  "Just trying this out...",
   "date":  "2014/01/01"
}
```



## 5、检查文档是否存在

```
如果只想检查一个文档是否存在 —— 根本不想关心内容 --那么用 HEAD 方法来代替 GET 方法。 HEAD 请求没有返回体，只返回一个 HTTP 请求报头：

HEAD http://localhost:9200/website/blog/123

如果文档存在，Elasticsearch 将返回一个 200 ok 的状态码。

HTTP/1.1 200 OK
Content-Type: text/plain; charset=UTF-8
Content-Length: 0


若文档不存在， elasticsearch 将返回一个 404 Not Found 的状态码：

HTTP/1.1 404 Not Found
Content-Type: text/plain; charset=UTF-8
Content-Length: 0
```

当然，一个文档仅仅是在检查的时候不存在，并不意味着一毫秒之后它也不存在：也许同时正好另一个进程就创建了该文档。



## 6、更新整个文档

```
在 elasticsearch 中文档是 不可改变的，不能修改它们。相反，如果想要更新现有的文档，需要重建索引或者进行替换，我们可以使用相同的 indexAPI 进行实现。
```

```
PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "I am starting to get the hang of this...",
  "date":  "2014/01/02"
}

在响应体中，我们能看到 Elasticsearch 已经增加了 _version 字段值：
{
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 2,
  "created":   false 
}

created 标志设置成 false ，是因为相同的索引、类型和 ID 的文档已经存在。
```

```
在内部，elasticsearch 已将旧文档标记为已删除，并增加一个全新的文档。尽管你不能再对旧版本的文档进行访问，但它并不会立即消失。当继续索引更多的数据， elasticsearch 会在后台清理这些已删除的文档。
```

```
在本章的后面部分，我们会介绍 update API，这个API 可以用于 partial updates to a document. 虽然它似乎对文档直接进行了修改，但实际上 elasticsearch 按前述完全相同方式执行以下过程：

1、从旧文档构建 JSON
2、更改该 JSON
3、删除旧文档
4、索引一个新文档

唯一的区别在于,  update API 仅仅通过一个客户端请求来实现这些步骤，而不需要单独的 get 和 index 请求。
```

## 7、创建新文档

```
当我们索引一个文档，怎么确认我们正在创建一个完全新的文档，而不是覆盖现有的呢？

请记住，_index _type _id 的组合可以唯一标识一个文档。所以，确保创建一个新文档的最简单办法就是，使用索引请求的 post 形式让 elasticsearch 自动生成唯一 _id：

POST /website/blog/
{ ... }
```

```
然而，如果已经有自己的 _id,那么我们必须告诉 elasticsearch，只有在相同的 _index _type _id 不存在时才接受我们的索引请求。这里有两种方式，他们做的实际是相同的事情。使用哪种，取决于哪种使用起来更方便。
```

```
第一种方法使用 op_type 查询 - 字符串参数：
PUT /website/blog/123?op_type=create
{ ... }

第二种是在 URL 末端使用 /_create 
PUT /website/blog/123/_create
{ ... }
```

```
如果创建新文档的请求成功执行， elasticsearch 会返回元数据和一个 201 created 的 HTTP 响应码。

另一方面，如果具有相同的 _index _type _id 的文档已经存在， elasticsearch  将会返回 409 conflict 响应码，以及如下的错误信息： 



{
   "error": {
      "root_cause": [
         {
            "type": "document_already_exists_exception",
            "reason": "[blog][123]: document already exists",
            "shard": "0",
            "index": "website"
         }
      ],
      "type": "document_already_exists_exception",
      "reason": "[blog][123]: document already exists",
      "shard": "0",
      "index": "website"
   },
   "status": 409
}
```



## 8、删除文档

```
删除文档的语法和我们所知道的规则相同，只是使用 DELETE 方法

DELETE /website/blog/123

如果找到该文档，elasticsearch  将要返回一个 200 OK 的HTTP 响应码，和一个类似以下结构的响应体。注意，字段  _version 值已经增加： 

{
  "found" :    true,
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 3
}

如果文档没有 找到，我们将得到 404 Not Found 的响应码和类似这样的响应体：
{
  "found" :    false,
  "_index" :   "website",
  "_type" :    "blog",
  "_id" :      "123",
  "_version" : 4
}
```

```
即使文档不存在 (Found 是 false), _version 值仍然会增加。这是 elasticsearch 内部记录本的一部分，用来确保这些改变在跨多节点时以正确的顺序执行。
```

```
正如已经在 更新整个文档 中提到，删除文档不会立即将文档从磁盘中删除，只是将文档标记为已删除状态。随着你不断的索引更多的数据， elasticsearch 将会在后台清理标记为已删除的文档。
```



## 9、处理冲突



```
在数据库领域中，有两种方法通常被用来确保并发更新时变更不会丢失：

悲观并发控制
这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此阻塞访问资源以防止冲突。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。


乐观并发控制
Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，如果源数据在读写当中被修改，更新将会失败。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。
```

## 10、乐观并发控制

```
elasticsearch 是分布式的。当文档创建、更新或删除时，新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许 顺序是乱的 。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。


当我们之前讨论 index ， GET 和 delete 请求时，我们指出每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。

我们可以利用 _version 号来确保 应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version 号来达到这个目的。 如果该版本不是当前版本号，我们的请求将会失败。
```

```
1.7以后的 es 不用 version 了 而是使用 if_seq_no 和 if_primary_term 来控制版本

这里就不详细记录了
```

## 11、文档的部分更新



### 更新和冲突

```
在本节的介绍中，我们说明 检索 和 重建索引 步骤的间隔越小，变更冲突的机会越小。 但是它并不能完全消除冲突的可能性。 还是有可能在 update 设法重新索引之前，来自另一进程的请求修改了文档
```



# 2、分布式文档存储

## 1、路由一个文档到一个分片中

```
当索引一个文档的时候，文档会被存储到一个主分片中。elasticsearch 如何知道一个文档应该存放到哪个分片中呢？ 当我们创建文档时，它如何决定这个文档应当被存储在分片1还是分片2中呢？
```

```
是根据下面的公式来的

shard = hash(routing) % number_of_primary_shards

routing 是一个可变值，默认是文档的 _id,也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards (主分片的数量)后得余数。这个分布在 0 到 number_of_primary_shard-1  之间的余数，就是我们所寻求的文档所在分片的位置。
```

```
这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
```

```
所有的文档API (get、index、delete、bulk、update、mget)都接受一个叫做 routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路有参数可以用来确保所有相关文档 -- 例如所有属于同一个用户的文档 -- 都被存储到同一个分片中。
```





# 3、搜索

## 1、空搜索

```
搜索API的最基础的形式是没有指定任何查询的空搜索 ，它简单地返回集群中所有索引下的所有文档：

GET /_search

返回的结果如下

{
   "hits" : {
      "total" :       14,
      "hits" : [
        {
          "_index":   "us",
          "_type":    "tweet",
          "_id":      "7",
          "_score":   1,
          "_source": {
             "date":    "2014-09-17",
             "name":    "John Smith",
             "tweet":   "The Query DSL is really powerful and flexible",
             "user_id": 2
          }
       },
        ... 9 RESULTS REMOVED ...
      ],
      "max_score" :   1
   },
   "took" :           4,
   "_shards" : {
      "failed" :      0,
      "successful" :  10,
      "total" :       10
   },
   "timed_out" :      false
}
```

```
hits

返回结果中最重要的部分是 hits, 它包含 total 字段来表示匹配到的文档总数，并且一个 hits 数组包含所查询结果的前十个文档。

在 hits 数组中每个结果包含文档的 _index 、 _type 、 _id ，加上 _source 字段。这意味着我们可以直接从返回的搜索结果中使用整个文档。这不像其他的搜索引擎，仅仅返回文档的ID，需要你单独去获取文档。

每个结果还有一个 _score ，它衡量了文档与查询的匹配程度。默认情况下，首先返回最相关的文档结果，就是说，返回的文档是按照 _score 降序排列的。在这个例子中，我们没有指定任何查询，故所有的文档具有相同的相关性，因此对所有的结果而言 1 是中性的 _score 。

max_score 值是与查询所匹配文档的 _score 的最大值。
```

```
took
took 值告诉我们执行整个搜索请求耗费了多少毫秒。
```

```
shards
_shards 部分 告诉我们在查询中参与分片的总数，以及这些分片成功了多少个失败了多少个。正常情况下我们不希望分片失败，但是分片失败是可能发生的。如果我们遭遇到一种灾难级别的故障，在这个故障中丢失了相同分片的原始数据和副本，那么对这个分片将没有可用副本来对搜索请求作出响应。假若这样，Elasticsearch 将报告这个分片是失败的，但是会继续返回剩余分片的结果。
```

```
timeout
timed_out 值告诉我们查询是否超时。默认情况下，搜索请求不会超时。 如果低响应时间比完成结果更重要，你可以指定 timeout 为 10 或者 10ms（10毫秒），或者 1s（1秒）：


GET /_search?timeout=10ms

在请求超时之前，Elasticsearch 将会返回已经成功从每个分片获取的结果


应当注意的是 timeout 不是停止执行查询，它仅仅是告知正在协调的节点返回到目前为止收集的结果并且关闭连接。在后台，其他的分片可能仍在执行查询即使是结果已经被发送了。

使用超时是因为 SLA(服务等级协议)对你是很重要的，而不是因为想去中止长时间运行的查询。
```

## 2、多索引，多类型

```
如果不对某一特殊的索引或者类型做限制，就会搜索集群中的所有文档。Elasticsearch 转发搜索请求到每一个主分片或者副本分片，汇集查询出的前10个结果，并且返回给我们。

然而，经常的情况下，你 想在一个或多个特殊的索引并且在一个或者多个特殊的类型中进行搜索。我们可以通过在URL中指定特殊的索引和类型达到这种效果，如下所示：
```

```
/_search 
	在所有索引中搜索所有的类型
	
/gd/_search 
	在 gb 索引中搜索所有的类型

/gd,us/_search
	在 gb 和 us 索引中搜索所有的文档
	
/g*,u*/_search
在任何以 g 或者 u 开头的索引中搜索所有的类型

 /gb/user/_search
在 gb 索引中搜索 user 类型

/gb,us/user,tweet/_search
在 gb 和 us 索引中搜索 user 和 tweet 类型

/_all/user,tweet/_search
在所有的索引中搜索 user 和 tweet 类型
```

```
当在单一的索引下进行搜索的时候，Elasticsearch 转发请求到索引的每个分片中，可以是主分片也可以是副本分片，然后从每个分片中收集结果。多索引搜索恰好也是用相同的方式工作的--只是会涉及到更多的分片。

搜索一个索引有五个主分片和搜索五个索引各有一个分片准确来所说是等价的。
```

## 3、分页

```
在之前的 空搜索 中说明了集群中有 14 个文档匹配了（empty）query 。 但是在 hits 数组中只有 10 个文档。如何才能看到其他的文档？

和 SQL 使用 LIMIT 关键字返回单个 page 结果的方法相同，Elasticsearch 接受 from 和 size 参数：

size 
	显示应该返回的结果数量，默认是 10
from
	显示应该跳过的初始结果数量，默认是 0
```

如果每页展示 5 条结果，可以用下面方式请求得到 1 到 3 页的结果：

```
GET /_search?size=5
GET /_search?size=5&from=5
GET /_search?size=5&from=10
```

```
考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的。
```

```
在分布式系统中深度分页

理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。

现在假设我们请求第 1000 页--结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。

可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。
```

## 4、轻量搜索

```
有两种形式的 搜索 API：一种是 “轻量的” 查询字符串 版本，要求在查询字符串中传递所有的 参数，

另一种是更完整的 请求体 版本，要求使用 JSON 格式和更丰富的查询表达式作为搜索语言。
```

```
查询字符串搜索非常适用于通过命令行做即席查询。例如，查询在 tweet 类型中 a 字段包含 elasticsearch 单词的所有文档：

GET /_all/tweet/_search?q=a:elasticsearch
```

```
下一个查询在 name 字段中包含 john 并且在 tweet 字段中包含 mary 的文档。实际的查询就是这样

+name:john +tweet:mary

但是查询字符串参数所需要的 百分比编码 （译者注：URL编码）实际上更加难懂：
GET /_search?q=%2Bname%3Ajohn+%2Btweet%3Amary


+ 前缀表示必须与查询条件匹配。
类似的， - 前缀表示一定不与查询条件匹配。

没有+ 或者 - 的所有条件都是可选的 -- 匹配的越多，文档就越相关。
```

### _all字段

```
这个简单返回包含 mary 的所有文档：
GET /_search?q=mary
```

```
之前的例子中，我们在 tweet 和 name 字段中搜索内容。然而，这个查询的结果在三个地方提到了 mary ：

有一个用户叫做 Mary
6条微博发自 Mary
一条微博直接 @mary
Elasticsearch 是如何在三个不同的字段中查找到结果的呢？

当索引一个文档的时候，Elasticsearch 取出所有字段的值拼接成一个大的字符串，作为 _all 字段进行索引。例如，当索引这个文档时：
{
    "tweet":    "However did I manage before Elasticsearch?",
    "date":     "2014-09-14",
    "name":     "Mary Jones",
    "user_id":  1
}

这就好似增加了一个名叫 _all 的额外字段：
"However did I manage before Elasticsearch? 2014-09-14 Mary Jones 1"
```

```
除非设置特定字段，否则查询字符串就使用 _all 字段进行搜索

在刚开始开发一个应用时，_all 字段是一个很实用的特性。之后，你会发现如果搜索时用指定字段来代替 _all 字段，将会更好控制搜索结果。当 _all 字段不再有用的时候，可以将它置为失效，正如在 元数据: _all 字段 中所解释的。
```

### 更复杂的查询

```
下面的查询针对 tweets 类型，并使用一下的条件：
name 字段中包含 mary 或者 john
data 值大于 2014-09-10
_all 字段包含 aggregations 或者 geo
```

```
+name:(mary john) +date:>2014-09-10 +(aggregations geo)

查询字符串在做了适当的编码后，可读性很差：

?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo)
```

```
从之前的例子中可以看出，这种 轻量 的查询字符串搜索效果还是挺让人惊喜的。 它的查询语法在相关参考文档中有详细解释，以便简洁的表达很复杂的查询。对于通过命令做一次性查询，或者是在开发阶段，都非常方便。

但同时也可以看到，这种精简让调试更加晦涩和困难。而且很脆弱，一些查询字符串中很小的语法错误，像 - ， : ， / 或者 " 不匹配等，将会返回错误而不是搜索结果。

最后，查询字符串搜索允许任何用户在索引的任意字段上执行可能较慢且重量级的查询，这可能会暴露隐私信息，甚至将集群拖垮。

因为这些原因，不推荐直接向用户暴露查询字符串搜索功能，除非对于集群和数据来说非常信任他们。

相反，我们经常在生产环境中更多地使用功能全面的 request body 查询API，除了能完成以上所有功能，还有一些附加功能。但在到达那个阶段之前，首先需要了解数据在 Elasticsearch 中是如何被索引的。
```



# 4、映射和分析

```
当摆弄索引里面的数据时，我们发现一些奇怪的事情。一些事情看起来被打乱了：在我们的索引中有12条推文，其中只有一条包含日期 2014-09-15 ，但是看一看下面查询命中的 总数 （total）：

GET /_search?q=2014              # 12 results
GET /_search?q=2014-09-15        # 12 results !
GET /_search?q=date:2014-09-15   # 1  result
GET /_search?q=date:2014         # 0  results !
```

```
为什么在 _all 字段查询日期返回所有推文，而在 date 字段只查询年份却没有返回结果？为什么我们在 _all 字段和 date 字段的查询结果有差别？

推测起来，这是因为数据在 _all 字段与 date 字段的索引方式不同。所以，通过请求 gb 索引中 tweet 类型的_映射_（或模式定义），让我们看一看 Elasticsearch 是如何解释我们文档结构的：
```

```json
GET /gb/_mapping


{
    "megacorp": {
        "mappings": {
            "properties": {
                "about": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "age": {
                    "type": "long"
                },
                "first_name": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "interests": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    },
                    "fielddata": true
                },
                "last_name": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "type": "keyword",
                            "ignore_above": 256
                        }
                    }
                },
                "properties": {
                    "properties": {
                        "interests": {
                            "properties": {
                                "fielddata": {
                                    "type": "boolean"
                                },
                                "type": {
                                    "type": "text",
                                    "fields": {
                                        "keyword": {
                                            "type": "keyword",
                                            "ignore_above": 256
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "tags": {
                    "type": "text",
                    "fielddata": true
                }
            }
        }
    }
}
```

```
基于对字段类型的猜测， Elasticsearch 动态为我们产生了一个映射。这个响应告诉我们 date 字段被认为是 date 类型的。由于 _all 是默认字段，所以没有提及它。但是我们知道 _all 字段是 string 类型的。

所以 date 字段和 string 字段 索引方式不同，因此搜索结果也不一样。这完全不令人吃惊。你可能会认为 核心数据类型 strings、numbers、Booleans 和 dates 的索引方式有稍许不同。没错，他们确实稍有不同。

但是，到目前为止，最大的差异在于 代表 精确值 （它包括 string 字段）的字段和代表 全文 的字段。这个区别非常重要——它将搜索引擎和所有其他数据库区别开来。
```



## 1、精确值VS全文

```
elasticsearch 中的数据可以概括的分为两类：精确值和全文。
```

```
精确值如它们听起来那样精确。例如日期或者用户 ID，但字符串也可以表示精确值，例如用户名或邮箱地址。对于精确值来讲，Foo 和 foo 是不同的，2014 和 2014-09-15 也是不同的。

另一方面，全文 是指文本数据（通常以人类容易识别的语言书写），例如一个推文的内容或一封邮件的内容。

全文通常是指非结构化的数据，但这里有一个误解：自然语言是高度结构化的。问题在于自然语言的规则是复杂的，导致计算机难以正确解析。例如，考虑这条语句：

May is fun but June bores me.
它指的是月份还是人？
```

```
精确值很容易查询。结果是二进制的： 要么匹配查询，要么不匹配。
这种查询很容易用 SQL 表示：
WHERE name    = "John Smith"
  AND user_id = 2
  AND date    > "2014-09-15"
```

```
我们很少对全文类型的域做精确匹配。相反，我们希望在文本类型的域中搜索。不仅如此，我们还希望搜索能够理解我们的 意图 ：

搜索 UK ，会返回包含 United Kindom 的文档。
搜索 jump ，会匹配 jumped ， jumps ， jumping ，甚至是 leap 。
搜索 johnny walker 会匹配 Johnnie Walker ， johnnie depp 应该匹配 Johnny Depp 。
fox news hunting 应该返回福克斯新闻（ Foxs News ）中关于狩猎的故事，同时， fox hunting news 应该返回关于猎狐的故事。
为了促进这类在全文域中的查询，Elasticsearch 首先 分析 文档，之后根据结果创建 倒排索引 。在接下来的两节，我们会讨论倒排索引和分析过程。
```

## 2、倒排索引

```
elasticsearch 使用一种称为 倒排索引的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。
```

例如，假设我们有两个文档，每个文档的 `content` 域包含如下内容：

1. The quick brown fox jumped over the lazy dog
2. Quick brown foxes leap over lazy dogs in summer

```
为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 词（我们称它为 词条 或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：
```

```
Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------
```

```
现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档：

Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
quick   |   X   |
------------------------
Total   |   2   |  1
两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。
```

但是，我们目前的倒排索引有一些问题：

- `Quick` 和 `quick` 以独立的词条出现，然而用户可能认为它们是相同的词。
- `fox` 和 `foxes` 非常相似, 就像 `dog` 和 `dogs` ；他们有相同的词根。
- `jumped` 和 `leap`, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。

使用前面的索引搜索 `+Quick +fox` 不会得到任何匹配文档。（记住，`+` 前缀表明这个词必须存在。）只有同时出现 `Quick` 和 `fox` 的文档才满足这个查询条件，但是第一个文档包含 `quick fox` ，第二个文档包含 `Quick foxes` 。



```
我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。

如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如：

- Quick 可以小写化为 quick 。
- foxes 可以 词干提取 --变为词根的格式-- 为 fox 。类似的， dogs 可以为提取为 dog 。
- jumped 和 leap 是同义词，可以索引为相同的单词 jump 。

现在索引看上去像这样：


Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
dog     |   X   |  X
fox     |   X   |  X
in      |       |  X
jump    |   X   |  X
lazy    |   X   |  X
over    |   X   |  X
quick   |   X   |  X
summer  |       |  X
the     |   X   |  X
------------------------
```

```
这还远远不够。我们搜索 +Quick +fox 仍然 会失败，因为在我们的索引中，已经没有 Quick 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询 +quick +fox ，这样两个文档都会匹配！

这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。

分词和标准化的过程称为 分析 ， 我们会在下个章节讨论。
```









